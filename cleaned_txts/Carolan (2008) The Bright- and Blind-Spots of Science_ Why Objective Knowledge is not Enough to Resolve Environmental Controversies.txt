See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/258130678
The Bright- and Blind-Spots of Science: Why Objective Knowledge is not Enough to Resolve Environmental Controversies
Article in Critical Sociology · September 2008 DOI: 10.1177/0896920508093365
CITATIONS                                                                                 READS 52                                                                                        492
1 author:
            Michael S Carolan             Colorado State University             163 PUBLICATIONS 5,519 CITATIONS
                SEE PROFILE
 All content following this page was uploaded by Michael S Carolan on 12 December 2014.
 The user has requested enhancement of the downloaded file.                       Critical Sociology                                        http://crs.sagepub.com
The Bright- and Blind-Spots of Science: Why Objective Knowledge is not             Enough to Resolve Environmental Controversies                                      Michael S. Carolan                                   Crit Sociol 2008; 34; 725                               DOI: 10.1177/0896920508093365
                 The online version of this article can be found at:                http://crs.sagepub.com/cgi/content/abstract/34/5/725
                                                   Published by:
                                    http://www.sagepublications.com
        Additional services and information for Critical Sociology can be found at:
                          Email Alerts: http://crs.sagepub.com/cgi/alerts
                      Subscriptions: http://crs.sagepub.com/subscriptions
                   Reprints: http://www.sagepub.com/journalsReprints.nav
              Permissions: http://www.sagepub.co.uk/journalsPermissions.nav
                  Citations http://crs.sagepub.com/cgi/content/refs/34/5/725
                  Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010 Critical Sociology 34(5) 725-740
                                                                                                        http://crs.sagepub.com
    The Bright- and Blind-Spots of Science: Why Objective      Knowledge is not Enough to Resolve Environmental                         Controversies
                                              Michael S. Carolan                                          Colorado State University, USA
Abstract This article investigates why science often does not speak with one voice within the context of environmental controversies. I argue that sociologists must be willing to turn to those processes and phenomena that are internal to science. In doing this, we find that many environmental conflicts are products, at least in part, of science itself. What is it about science that helps to breed these conflicts? In answering this question, this article first reflects upon the effects that disciplinary and methodological diversity have on scientific disputes. Attention then turns to the topics of proof and consensus, highlighting how these terms have often been employed to amplify conflict. I then speak to how science presupposes values. The article concludes by making policy-relevant suggestions about how to ‘do’ environmental science in a way that acknowledges its various epistemic bright- and blind-spots.
Keywords consensus, controversy, global climate change, proof, uncertainty
Introduction Much has been written of late concerning the distorting forces that shape scientific discourse (Austin and Phoenix, 2005; Freudenburg and Gramling, 2002; Kleinman, 1995; Kraft, 2000; McCright and Dunlap, 2000, 2003). While I am also concerned about how, for example, ideology, money, and/or political power can unduly influence science, I cannot help feeling slightly uncomfortable with what such arguments imply. For when we speak of the politicization of science, we are tacitly accepting that real science is apolitical, certain, and value-free.     Instead, this article highlights why we would do well to turn our gaze back upon science. In doing this, we find environmental controversies to be, at least in part, the result © 2008 SAGE Publications (Los Angeles, London, New Delhi and Singapore)                   DOI: 10.1177/0896920508093365
                      Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010 726   Critical Sociology 34(5)
of processes internal to science. Until we understand how science itself can breed controversy and conflict, we will continually be off the mark as we work toward resolution. Thus, rather than walking down the well-worn path concerning the politicization of science (e.g. Kitcher, 2001; McCright and Dunlap, 2000, 2003; Rayner, 2003), I opt for a different, less traveled route: to highlight that environmental contestation – involving seemingly incommensurable positions between so-called ‘experts’ – need not be linked solely to politics or ideology but to science itself.    The implications of this argument are more than academic. For if science is as much the problem as it is the solution, we will have to seriously rethink its role for resolving environmental problems. Research, therefore, that focuses squarely on the effect of external variables on science will continue to miss an important and perhaps even deeper source of contestation. And until this source is adequately brought to light and discussed, the contestation of science will continue without us fully understanding why.    This article begins by investigating the reasons why scientists may not always speak in a unified voice when dealing with environmental controversies, highlighting first the effect that disciplinary and methodological diversity can have on scientific disputes. I then turn to the topics of proof and consensus within science, highlighting how these artifacts have been used to create unnecessary conflict in environmental disputes. I then turn directly to the issue of how science requires value judgments. Gleaning insights from the previous section, the article concludes by making policy-relevant suggestions about how to ‘do’ environmental science in a way that acknowledges its epistemic limits.
The Multiple Ways of ‘Seeing’ in Science As has been well detailed, ‘essential’ criteria upon which to define science from non-science have proven elusive (Gieryn, 1983, 1995; Jasanoff, 1987a; Kuhn, 1970 [1962]; Mulkay, 1976). There is no methodological mode of inquiry used only by scientists (Haack, 2003). If science involves a different mode of inquiry, it is because its practitioners investigate with care. This is what Kuhn was getting at when he differentiated between ‘observation’ (what scientists do) and ‘perception’ (a less methodical form of inquiry): the former he described as ‘collected with difficulty’ while the latter he referred to as ‘the given’ (1970 [1962]: 126). Even so, scientists are not all seeing. Simply because scientific observations are conducted with care and difficulty does not mean they are ‘pure’ – that they exist independent of a social context.    Latour (1992: 266) provides us with the following suggestive metaphor: ‘Scientific facts are like trains, they do not work off their rails. You can extend the rails and connect them but you cannot drive a locomotive through a field.’ One could extend this metaphor to the scientific disciplines, in that they too work best within their methodological and epistemic ‘rails.’ The disciplines serve an important analytic purpose: namely, they break down into epistemologically manageable parts what is in reality an immensely complex world (Bhaskar, 1978; Carolan, 2005a, 2005b; Collier, 1994). Yet, there is a flip side to this philosophical coin: to speak of say, global climate change
           Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010                                                                   Carolan: Environmental Controversies 727
or genetically modified organisms – particularly from the perspective of policy and regulation – involves an examination of the entire field (not just where the various scientific ‘rails’ run).    Daniel Sarewitz (2004) makes a similar point when speaking of the controversy that erupted following the publication of an article in Nature by Ignacio Chapela, a microbial ecologist, and his graduate student, David Quist. This (in)famous article documented the occurrence of transgenic corn in Mexico, despite the fact GM corn was banned by its government (Quist and Chapela, 2001). While others sought to locate the controversy that erupted over the publication of this article within various biases attributed to either side of the debate (McAfee, 2003; Scott, 2003), Sarewitz opted for a different route. Rather than taking the often traveled path and examine forces external to science, Sarewitz approached the controversy by examining how science itself may have contributed to this debate. Particularly, he centered on the point that the two sides of the debate – those generally supportive of the article and those against it ever having seen the light of day – tended to break down along disciplinary lines (at least among those within the life sciences). After analyzing the debate between scientists, and the disciplinary locations of the various participants, Sarewitz arrived at the following conclusion:
    Yet on another level that was never discussed, the disciplinary structure and disunity of     science itself was at the roots of the controversy. The two sides of the debate represented     two contrasting scientific views of nature – one concerned about complexity,     interconnectedness, and lack of predictability, the other concerned with controlling the     attributes of specific organisms for human benefit. In disciplinary terms, these competing     views map onto two distinctive intellectual schools in life science – ecology and     molecular genetics (2004: 391).
    Since it is not possible for us to take the proverbial ‘view from nowhere’ – the so-called ‘God’s eye view’ (e.g. Fox-Keller, 1985; Haraway, 1991; Harding, 1991) – all knowledge (all ‘views’) is limited. Such epistemic constraints are often grounded in the disciplinary conventions of the analyst. The world is simply too complex for us to be able to take it all in, involving artifacts, forces, and tendencies that in some cases can only be observed abductively (phenomena that can be explained if forces/tendencies were present and very difficult to explain if they were not). In light of such ‘abundance’ (Feyerabend, 2000), cause-and-effect can be particularly difficult to establish. Compared to the closed environment of the laboratory, the world is an open system (Bhaskar, 1978). Thus, even the very act of studying the world can add complexity to it, because doing so introduces the cognitive states (and behaviors, potential policy extensions, etc.) of those doing the research (Rosenberg, 1994).     This limited epistemic outlook thus translates into only suggestive views of causality (save, perhaps, for the most trivial of cases). When assessing risk, for instance, it is simply not possible for researchers to take into consideration every variable and synergistic interaction (Jasanoff, 1999). There is simply not enough money or computational power in the world for such a Herculean task. Rather, researchers focus upon a few key, empirically
                   Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010 728    Critical Sociology 34(5)
observable variables and relationships, and from this attempt to provide reasonable suggestions as to what the particular risk/threat in question is (Cohrssen and Covello, 1989).     Since ‘the facts’ surrounding a controversy can never be arranged to reveal a picture of reality in its totality, decisions have to be made about how best to fill in the gaps between those many pieces; to put it another way, decisions are made that make it appear as though the space between the ‘rails’ of the various disciplines have been seamlessly closed. We choose, in other words, which facts to look at and which to ignore, which is to say we choose what constitutes a ‘fact’ and what does not (Jasanoff and Wynne, 1998; Wynne, 2001). From this, we then arrange those ‘facts’ in ways that we find useful according to institutional norms, values, and disciplinary constrictions. This point, for example, was illustrated by Sarewitz (2004) in his aforementioned examination of the controversy surrounding the Nature publication concerning (the alleged) occurrence of GM corn in Mexico. We can therefore think of disciplines as providing context for scientists, which, in turn, helps give shape to the content of what counts as ‘important’/ ‘unimportant.’     Part of this epistemic discrepancy across disciplines resides in the various methods they employ. In short, different disciplines tend to ‘see’ different aspects of the world because of the methods they use. And, as others have argued, the methodological outlook taken not only shapes what we observe, but also what counts as ‘evidence’ and thus as ‘fact’ (Carolan, 2004; Law and Urry, 2004; Mol, 2002).     This methodological diversity is reflected in the fact that philosophers of science have failed to arrive at a consensus when it comes to constructing a universal, logical claim about which scientific method (quantitative, qualitative, etc.) and form of evidence (experiential, abductive, etc.) best corresponds to the world ‘out there’. Indeed, most philosophers of science realize that the correspondence theory of truth is a chimera. Thus, a further source of contestation between scientists can lie in their valuing competing forms of evidence differently, as a result of having been ‘disciplined’ into valuing methodological techniques differently. And since sound logical arguments can be summoned behind each methodological form (and each corresponding type of evidence), we cannot say that one is inherently ‘better’ than another. As argued by Oreskes:
      When it comes to evaluating conflicting evidence, people tend to trust evidence of the       kind which they and their close colleagues have dedicated their lives to obtaining, in part       for social reasons, and in part because they have an intellectual, aesthetic, or ethical       affinity for that kind of scientific work, which helps to explain why they chose to pursue       that kind of research in the first place. Often these commitments are both affective and       epistemic. Field scientists like the field work […] and they also believe it to be more likely       to capture the basic truths about the natural world, messy though it may be. In contrast,       laboratory scientists enjoy working in the lab […] and they also believe it to produce       knowledge of greater specificity and rigor than field science. (2004a: 375)
   So, again, we find yet another instance of where seemingly incommensurable positions between scientists can be linked to something inherent to science itself, rather than due purely to some external distorting force like money, politics, or ideology. When viewed
             Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010                                                                  Carolan: Environmental Controversies 729
in this light, we can begin to understand why science is as much the source of many environmental controversies as it is the solution.
Proof and Consensus in Science In light of these divergent epistemic lenses, how, then, is consensus ever established within science? Naomi Oreskes (1999, 2004a) provides an insightful analysis of how scientific acceptance occurs in science, even in the absence of proof. Specifically, she highlights the tremendous scientific consensus that emerged around Wegener’s theory of continental drift in the first half of the 20th century followed by plate tectonics in the 1960s and 1970s, both of which importantly occurred without direct evidence to support (let alone prove) either theory. Rather, relevant inferences were abductive in both instances.     Yet, even after the mid-1980s, when plate tectonics was empirically confirmed, the consensus (or what science and technology studies scholars call ‘closure’ (Bijker, 1995; Gieryn, 1983, 1995; Jasanoff, 1987a)) around the veracity of this theory (or mechanism) has not been complete. For example, outliers in the data continue to exist. To say plate tectonics, in a strict philosophy of science sense, has been ‘confirmed’ is not to say it has been ‘proven’. The robust consensus that exists within the scientific community today concerning plate tectonics should therefore not be confused with universal consensus. A small number of Earth scientists continue to argue for an alternative explanation of the data, for example, from which has emerged the Expanding Earth Theory (e.g. Scalera and Karl-Heinz, 2003).     It is important for us to remember that outliers may, in the end, turn out to be valid observations and end up vindicating those including such data in their alternative theories. In highlighting this point, I am not attempting to undermine or place into question the validity of plate tectonics. Rather, my intent is more general: to provide a reminder of the epistemic limits of science. My point is that outliers are more defined by normative standards of how individuals/groups think the world ought to look – and which data should be included in a model – than they are based upon some pure scientific rationale. Is it any surprise, then, that as scientific issues become more relevant to policy, defenders of the status quo are assembled in increasing numbers to challenge interpretations of how outlier data are treated and defined?     Oreskes (2004a: 371) asks this very question in the context of continental drift theory: namely, had continental drift theory been relevant to the question of public policy, would robust consensus have coalesced around this theory as quickly as it did? Along similar lines, Sarewitz (2004) writes on a prediction made by seismologists from the US Geological Survey, who estimated with 95 per cent probability that a mid-size earthquake would occur along the Parkfield segment of the San Andreas Fault by the year 1993. Importantly, this estimation was also overwhelmingly accepted by the scientific community at the time it was made in 1985. Yet, 15 years after 1993, no earthquake has yet occurred in this area. With that, Sarewitz (2004) wonders if such a prediction would have
                  Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010 730   Critical Sociology 34(5)
been as strongly accepted by the scientific community had it been predicted for an earthquake in San Francisco.     At the time, the Parkfield fault segment ran through a rural, agricultural-dependent region of the state. As such, there was less political, economic, and social-psychological pressure for the scientists to get the science ‘right’. There was, in other words, less at stake in this prediction than if, say, it was meant for a densely populated urban area. If the prediction was meant instead for San Francisco, as argued by Sarewitz (2004: 393), ‘scientific and political scrutiny of the prediction would have greatly intensified, the pressure on the scientists to be ‘right’ would have been intense, and the population of scientists and perhaps of disciplines involved in the prediction process would have expanded.’ And this expansion of science, as discussed earlier, would have likely introduced further discrepancies as to what the valid facts of the situation were at the time.     For another example, take the political and scientific contestation that surrounds the issue of global climate change (see e.g. Demeritt, 2001; McCright and Dunlap, 2000; Taylor and Buttel, 1992; Timmons Roberts, 2001; Yearly, 1996). One notable example comes from McCright and Dunlap (2003). In this particular piece, they describe how a shift in the political opportunity structure created by the 1994 Republican takeover of Congress provided an opening for a powerful challenge to the scientific consensus concerning the existence of global warming as a ‘problem’. While their analysis is both thoughtful and thorough, I cannot help but think they have missed an important piece of the puzzle. One could perhaps think of this missing piece as a type of precipitating structure, which moved the topic of climate change from being largely a scientific issue to one that was equally social, political, and economic. Specifically, what effects did the looming Kyoto Protocol – where 160 nations met in Kyoto, Japan, in December 1997, to discuss the reduction of carbon dioxide emissions – have on creating pressures in the mid-1990s to reduce the (inherent) uncertainties surrounding the science of climate change?     Importantly, the Kyoto Protocol made the question of global climate change relevant to public policy, and with that, not surprisingly, more people were attracted to this question than might have been otherwise. In other words, Kyoto increased the need in the eyes of many to get the science ‘right’, given its now more immediate economic and political consequences. Rather than being surprised by this finding, as McCright and Dunlap (2003) appear to be, I would have been surprised if greater scrutiny were not placed on the science of the matter and the uncertainties therein contained. And that is, in part, what we are continuing to see in the climate change debate today: outliers are now being scrutinized – by the so-called ‘skeptics’ – that otherwise might not have been.     This is not to place into question McCright and Dunlap’s analysis but to give it further context. My point is that the science of global climate change is being politicized because it can be, for reasons related to artifacts internal to science. Something about science lends itself to such politicization. And we need to get at what that ‘something’ is if we hope to understand the underlying complexities of environmental controversies.     Turning to a recent piece by William Freudenburg (2005), we find another example of how impending institutional factors can increase ‘the science’ – and thus the uncertainty and controversy – surrounding a particular issue. In this case, an anticipated court
           Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010                                                                   Carolan: Environmental Controversies 731
battle, much like the looming Kyoto Protocol described earlier, served as the institutional catalyst that increased the stakes surrounding the veracity of the science in question. Specifically, Freudenburg documents how corporations subtly work to, in his own words, ‘seed science’: ‘As with literal “cloud-seeding” … the company in question worked with ‘clouds’, or professors, that were already in roughly the ‘right’ position, rather than trying to recruit professors who would not otherwise have been found anywhere in the vicinity.’ (2005: 26)     While Freudenburg privileges science, in that he fails (or simply chooses not) to wonder if there is anything about science itself that allows such ‘seeding’ to occur, he does highlight how scientific controversies need not be solely the result of a willful distortion of the facts on the part of the experts. Yet, an alternative metaphor to apply to this case might be ‘fishing’. That is, the companies in Freudenburg’s research were ‘fishing’ for experts in roughly the correct positions (in terms of their disciplinary, methodological, and theoretical locations) who interpret ‘the facts’ in a manner consistent with their own (or in a manner that is consistent with their defense, when speaking in the context of a pending lawsuit).     As Freudenburg notes, these experts thus need not be intentionally altering their findings to arrive at their conclusions. Rather, they may have simply had a different understanding, relative to the general scientific field, of what counts in terms of valid data. And the goal of such fishing expeditions: to ‘catch’ just a few of these experts. For, in most cases at least, the objective is not to win over mainstream, peer-reviewed science to their side of the debate but to create a wedge issue, which, in turn, helps to create uncertainty in the eyes of the public (even if, as in the case of global climate change, a robust consensus exists among experts).     The media’s balancing norm makes such ‘fishing expeditions’ extremely effective in shaping public opinion. As Gitlin (1980) has argued, controversial news stories follow a ‘pro’ and ‘con’ model, where both sides of a debate are presented in the name of presenting news in an ‘objective’ manner (even if that means creating the perception of scientific uncertainty when in fact there is consensus). This norm, however, results in the perpetuation of extreme viewpoints that often have little acceptance in the wider scientific community, which makes it an attractive mechanism for proponents of the status quo to create a justification for political inaction (Freudenburg and Buttel, 1999).     Indeed, there are very few instances of where an impending decision has not increased the contestation of scientific knowledge claims. The Montreal Protocol (that mandated the gradual phase out of CFCs) comes close to representing such a case. Yet, in this instance, far less was at stake than we might think. For example, DuPont had already invented CFC alternatives, so industry interests were minimally threatened with such a phase out (Rowlands, 1993). Thus, even if the scientific case against CFCs was not airtight, in the sense of not having proof (because, again, proof in science is a chimera), a precautionary posture was economically and politically palatable to most stakeholders. Were those alternatives not available, which thus would have made the stakes greater for powerful stakeholders, I doubt that the outcome would have been the same (or, at least, the debates leading up to the Montreal Protocol would have been much more contentious than they were).
                   Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010 732   Critical Sociology 34(5)
    Again, the best science can do is provide a robust (not universal) consensus. What then does this mean when applied to, say, global climate change? As Oreskes (2004b) details in a widely discussed article in the journal Science, there is tremendous scientific consensus among the experts as to the existence of anthropogenic climate change. If we truly believe that science should help to guide policy, then we would follow that consensus. To do otherwise is to distort what science is. And that is no less appalling than where scientific evidence is intentionally distorted (or ‘unfavorable’ findings repressed) so as to support a particular viewpoint or the status quo: see e.g. Glantz et al. (1996) and Warner (1986) for examples of how the tobacco industry manufactured scientific findings to support its position.
Why Science Presupposes Value Statements I have thus far spoken to how science is, in very subtle ways, a social (and thus implicitly value-laden) activity. In this section, I speak specifically to how science presupposes values. Take, for example, the underlying normative assumptions of predictive models.     One place where we see values tacitly part of the modeling process is in the determination of confidence limits, which amounts to an imposition of a particular level of burden of proof. Confidence levels, however, are not objectively given. Rather, they are a reflection of values, preconceived systems of order, and beliefs. Nevertheless, results which fail to meet this prescribed threshold are rejected and forgotten, while ‘acceptable’ results become naturalized as objective fact.     Further examples of values that are internal to science can be found within the very words it uses to speak of its objects of study. While an argument could be made that all words are value-laden to at least some degree, a less contentious position can be staked out by pointing to the metaphorical exuberance found in the environmental science lexicon. Ecosystem health, ecosystem integrity, and alien species; terms such as these imply a preferred state of things. They imply, in other words, how we think the world ought to look (Carolan, 2006a). Even a seemingly objective term like ‘pollution’ presupposes some expectations as to what the world should look like. For, in the end, recognizing something as a ‘problem’ requires a pre-existing set of values as to what is ‘normal’, ‘natural’, and thus ‘right’.     Or take the frequent attempt among scientists, politicians, and the public to associate the ‘health’ or ‘integrity’ of an ecosystem with higher biological diversity (Wilson, 1992). Yet again, science alone cannot hierarchically rank ecosystem states in terms of their inherent superiority (e.g. high biological diversity) or inferiority (e.g. low biological diversity) (Lackey, 2001; Lancaster, 2000). We make those preferences due to cultural beliefs as to what we think nature should look like (Kapustka and Landis, 1998).     Admittedly, this ‘privileging’ of biodiversity is in part derived, at least among biologists, from theoretical implications implicit in studies bringing evolutionary theory to bear on the study of ecological niches. Even so, we must understand the operational and conceptual ambiguity inherent to the term ‘biodiversity’. In short, biodiversity is not objectively given. As others have detailed, for example, how one chooses to operationalize and define
           Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010                                                                  Carolan: Environmental Controversies 733
‘species’ – reflecting what biologists and philosophers of biology refer to as the species problem – alters significantly how biodiversity is empirically measured (Isacc et al., 2004).     Case in point: the biological species concept (arguably the most widely used of all species concepts). As Mayr (who, along with Dobzhansky, 1937, first forwarded this concept), explains: ‘species are groups of interbreeding natural populations that are reproductively isolated from other such groups’ (1970: 12). Yet, most biologists allow for some gene flow between species when applying the biological species concept (Hey, 2001). This then begs the question: when should two populations be defined as distinct species – when they are 99 per cent, 80 per cent, 51 per cent, or 10 per cent reproductively isolated? An answer to this question cannot be arrived at through objective measures alone; it is a matter of value judgments, not objective fact (Hendry et al., 2000). And terms predicated on one’s working definition of species, like biodiversity, must likewise be understood as being similarly ambiguous and normatively grounded.     Even conceptions of uncertainty tacitly rest upon value judgments. Uncertainty is a product of how ‘objectives’ are defined according to the scientific problem at hand, which leads to different conceptions of what is important and what we need to further investigate and/or estimate (Sarewitz, 2004; Shackley et al., 1998; Wynne, 2001). For example, uncertainty can vary according to how one decides evidence should be evaluated – that is, should it be evaluated in isolation or in relation to other pieces of evidence?     The US Supreme Court, for instance, ruled in General Electric Co. v. Joiner (1997) that judges should evaluate elements of evidence separately rather than in their totality. In doing this, the Court created a standard for evaluating knowledge that heightened uncertainty to a level that would not have otherwise existed if they ruled to evaluate evidence in its aggregate. This ruling is not, however, based upon some objectively given criteria for distinguishing between sound and unsound evidence. Rather, it involves claims about the way the world is, which are in reality based upon tacit assumptions concerning the way the world ought to be organized (Jasanoff, 2005b). Indeed, beyond being antithetical to most precautionary policies, this evaluative approach taken by the Court fails to grasp how evidence can interlock in a manner that makes the whole epistemologically greater than the sum of its parts. As Haack explains:
    [E]vidence of increased incidence of a disease among people exposed to a suspected     substance may interlock with evidence that animals biologically similar to humans are     harmed by exposure to that substance and evidence indicating what chemical mechanism     may be responsible, to support the claim that this substance causes, promotes, or     contributes to the disease, much more strongly than any of these pieces of evidence alone     could do. However, the interlocking will be less robust if, for example, the animals are     unlike humans in some relevant way, or if the mechanism postulated to cause damage is     also present in other chemicals not found to be associated with an increased risk of     disease, and so on (2005: S69-S70).
  In being made more aware of the values that underlie so-called objective, scientific debates we may find that some of today’s most heated environmental conflicts are
                  Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010 734   Critical Sociology 34(5)
ultimately the result of differing value positions (Carolan, 2006b). That is, while these controversies may appear on the surface to rest on disputed questions of fact, beneath often reside differing positions of value; values that can give shape to differing understandings of what ‘the facts’ are.    Along these lines, a number of studies have detailed how Britain and the USA weigh evidence differently when assessing risk (Gillespie et al., 1979; Jasanoff, 1986, 1987b, 1995, 2005a). According to this research, ‘scientific evidence was shown to carry different weight in different policy environments, its interpretation conditioned by homegrown traditions of legal and political reasoning and habits of deference or skepticism toward expert authority’ (Jasanoff, 2005a: 17). And even when policymakers in these two countries reach similar conclusions, they often do so by way of differing routes of ethical and legal reasoning (Brickman et al., 1985; Jasanoff, 1995, 2005a).
Science: Recognizing its Limits Where does this leave us, then, in our quest to reduce controversy over socio-environmental problems? If salvation cannot be found in more science, what can we turn to so as to resolve these seemingly intractable disputes?    What is needed is not more and/or better science but more and/or better mechanisms to bring those hidden values, which give meaning to ‘the facts’ of the matter, to the forefront of the discussion (Fischer, 2000; Sarewitz, 2004; Wynne, 2001, 2002). Until those underlying beliefs that inform social and policy goals about how the world ought to look can be articulated and some agreement reached on them, resources will continue to be spent on the impossible task of ascertaining proof. Beyond being an impossible task, the goal of more science in the name of relinquishing uncertainty is also (often) a meaningless one. For such an expectation is based upon the false belief that such debates reside in questions of pure fact, rather than realizing that their roots lie (in most cases at least) within differing value orientations. Science itself rarely provides sufficient basis for selecting between different courses of action, given that such action inevitably involves beliefs as to what the future should look like (Sarewitz, 1996). From, for example, whether or not the risks of DDT exceed its benefits, to what amount of global warming is considered ‘safe’; such questions speak to peoples’ conceptions of the world, which cannot be fully articulated through science alone.    Calls for more science also risk limiting which facts count and which do not. In scientific debates, only that which can be quantified matters. As others have argued, calculability implies objectivity, which, in turn, implies that which is scientific (Daston, 1992). For example, Feldman (2004), in his examination of the ‘culture of objectivity’ at NASA, describes some of the pitfalls that came from placing too much evaluative weight on ‘objective’ knowledge in the context of evaluating risks.1 Describing the decision making processes that led up to both the Challenger and Columbia disasters, Feldman notes how the engineers failed to ask the important qualitative questions of why, believing their objective, quantitative knowledge to be superior.
           Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010                                                                   Carolan: Environmental Controversies 735
    In the context of the Challenger case, the O-rings had repeatedly eroded in the early 1980s during every flight. Yet hot motor gases had never eroded the primary field joint worse than 0.053″. NASA engineers, however, had determined that the primary would still seal with erosion of 0.095″. In making this determination, they concluded that 0.090″ would constitute the ‘safety margin’. And as such, it was believed an erosion of 0.053″ to be well within the margins of what was deemed an acceptable risk.     Thus, instead of, for example, asking the qualitative questions of why 0.053″ – e.g. why not more or less erosion? – engineers focused instead on the objective, quantified fact that it was 0.053″ and thus not above the prescribed safety margin of 0.090″. In the minds of NASA engineers and managers, that piece of quantitative data was all that they needed to know to determine the risk to future flights (coupled with the fact that 0.053″ had not resulted in a ‘system failure’ in past flights). Feldman argues that the reason for this is because the former (qualitative, contextual data) cannot be readily quantified. And in NASA’s ‘culture of objectivity’, only quantified data were allowed to challenge decisions from ‘above’ (from management). In his own words,
    [I]nsistence on objective data narrowed the range of legitimate debate, thus giving     political advantage to those who were more skilled in using the rhetoric of objectivity or     who controlled the resources for producing ‘objective’ data … In the latter case, it was     management who had an advantage in forcing consensus because of their control over     resources, careers and decision making. Furthermore, management’s own career success     was directly tied to the accomplishment of organizational goals … thus bringing the     definition of objectivity into alignment with the accomplishment of these goals.     (Feldman, 2004: 703)
    Another way to think about the difference between objective (standardized/ quantitative) and non-objective (non-standardized/non-quantitative) knowledge is to view it as involving a distinction between quantity and quality. Many environmental ‘skeptics’ prefer to reduce human concerns to the lowest common denominator, which can be easily quantified: e.g. how many lives have been lost, saved, or fed with a given technology? (e.g. Bolch and Lyons, 1993; DeGregori, 2001, 2004; Huber, 1999) As Lomborg (2001: 11) remarks, ‘[my goal is] counting lives lost from different problems.’ While at the surface this may appear a laudable goal, it speaks nothing about the quality of these lives being lived. Of course, what is needed is an understanding based upon both quantity and quality. The latter, however, is often kept from objective environmental debates because it relies precisely on those things that cannot be counted, but which for most people matter just as much as things that can be unproblematically added and subtracted.     This brings us back to an earlier point: what is needed is not more and/or better objective science. This will only further squeeze out those people whose positions cannot easily be quantified. Instead, what are required are more and/or better political mechanisms to bring those hidden values, which lie within science, to the forefront of the discussion. In doing this, both facts and values must be discussed together, so that a better understanding can emerge as to how the latter (values) gives shape to interpretations of the former (facts).
                   Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010 736    Critical Sociology 34(5)
Doing this would therefore force politicians to explain their decisions beyond simply justifying their action/inaction on the tired statement ‘This is what the science says’, in the hopes of absolving themselves of any responsibility for their (in)actions.     Thus, if politicians choose to not act (such as in the context of global climate change), they will no longer be able to claim they are simply ‘waiting for more science to inform their decision’, and leave it at that. For such inaction says something to how they think the future ought to look. And as representatives of their constituents back home, politicians should be made to speak to those underlying value judgments (see also Sarewitz, 2004; Wynne, 2001).     Yet, perhaps the best way to ensure that politicians do not continue to unreflexively play the ‘more science’ card is to include others, and the value judgments of others, in the decision making process. One mechanism successfully employed to achieve such ends is the consensus conference (also known as ‘citizens’ juries’). Consensus conferences often involve two phases: in the first, a diverse group of citizens take testimony from various experts and interest groups; in the second, these citizens deliberate among themselves to arrive at policy guidelines, which are then given to the legislative body of the government (Fuller, 2002). Having first originated in Germany and the USA in the 1960s, consensus conferences have repeatedly demonstrated how so-called ‘lay’ individuals can make well reasoned policy decisions involving complex issues. Moreover, unlike stakeholder panels, consensus conference guidelines are binding on science and technology legislation, although outcomes can be revised in the future if consequences and data change (Fuller, 2006). This makes them more than simply mechanisms of appeasement, which merely have the facade of ‘public engagement’. The public engagement of consensus conferences is real. In some respects, then, consensus conferences offer a ‘third way’ for public involvement in science and technology. As Steve Fuller explains,
      So-called public-understanding-of-science campaigns have succeeded in drumming up       interest in science without necessarily providing outlets for expressing and applying that       interest. The opposite responses of the USA and Europe to the introduction of       genetically modified organisms into food production illustrate the problem. Without       something like consensus conferences to focus collective thought and action, people will       respond as either passive consumers or militant protesters. Neither constitutes an       adequate public engagement with science. (2006: 170)
    In conclusion, sociologists must not only ask, ‘How has science become politicized?’ but also ‘What is it about science that allows seemingly inextricable positions to emerge in the first place?’ We can no longer afford to privilege science, believing that environmental controversies are purely the result of something external to it. For as long as we continue down this unabashedly naive road about what science is, and what it is capable of doing, we will continue to fail to reach any sort of meaningful consensus on these matters. Rather than privileging it, sociologists must be willing to examine science itself when seeking to understand environmental conflicts and controversies. For, ultimately, it is here – in the brightand blind-spots of science – where the roots of much of this controversy reside.
            Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010                                                                     Carolan: Environmental Controversies 737
Note 1 For an alternative interpretation of the Challenger disaster, see Vaughan (1996).
References Austin, A. and Phoenix, L. (2005) The Neoconservative Assault on the Earth: The Environmental    Imperialism of the Bush Administration. Capitalism Nature Socialism 16(2): 25–43. Bhaskar, R. (1978) A Realist Theory of Science. Harvester Press: Hassocks. Bijker, W. (1995) Of Bicycles, Bakelites, and Bulbs: Toward a Theory of Sociotechnical Change. MIT Press:    Cambridge. Bolch, B. and Lyons, H. (1993) Apocalypse Not: Science, Economics, and Environmentalism. CATO    Institute: Washington, DC. Brickman, R., Jasanoff, S. and Ilgen, T. (1985) Controlling Chemicals: The Politics of Regulation in Europe    and the United States. Cornell University Press: Ithaca. Carolan, M.S. (2004) Ontological Politics: Mapping a Complex Environmental Problem. Environmental    Values 13(4):497–522. Carolan, M.S. (2005a) Realism without Reductionism: Toward an Ecologically Embedded Sociology.    Human Ecology Review 12(1): 1–20. Carolan, M.S. (2005b) Society, Biology, and Ecology: Bringing Nature back into Sociology’s    Disciplinary Narrative through Critical Realism. Organization and Environment 18(4): 393–421. Carolan, M.S. (2006a) The Values and Vulnerabilities of Metaphors within the Environmental Sciences.    Society and Natural Resources 19(10): 921–30. Carolan, M.S. (2006b) Scientific Knowledge and Environmental Policy: Why Science Needs Values.    Environmental Sciences: The Journal of Integrative Environmental Research 3(4): 229–37. Cohrssen, J. and Covello, V. (1989) Risk Analysis: A Guide to Principles and Methods for Analyzing Health    and Environmental Risks. Executive Office of the President of the USA, Council on Environmental    Quality: Washington, DC. Collier, A. (1994) Critical Realism. Verso: London. Daston, L. (1992) Objectivity and the Escape from Perspective. Social Studies of Science 22(4): 597–618. DeGregori, T. (2001) Agriculture and Modern Technology: A Defense. Iowa State Press: Ames. DeGregori, T. (2004) The Origins of the Organic Agriculture Debate. Iowa State Press: Ames. Demeritt, D. (2001) The Construction of Global Warming and the Politics of Science. Annals of the    Association of American Geographers 91(2): 307–37. Dobzhansky, T. (1937) Genetics and the Origin of Species. Columbia University Press: New York. Feldman, S. (2004) The Culture of Objectivity: Quantification, Uncertainty, and the Evaluation of Risk    at NASA. Human Relations 57(6): 691–718. Feyerabend, P. (2000) The Conquest of Abundance. University of Chicago Press: Chicago. Fischer, F. (2000) Citizens, Experts, and the Environment: The Politics of Local Knowledge. Duke University    Press: Durham. Fox-Keller, E. (1985) Reflections on Gender and Science. Yale University Press: New Haven. Freudenburg, W. (2005) Seeding Science, Courting Conclusions: Re-examining the Intersection of    Science, Corporate Cash, and the Law. Sociological Forum 20(1): 3–33. Freudenburg, W. and Buttel, F. (1999) Expert and Popular Opinion Regarding Climate Change in the    United States. R. Coppock et al. (eds) Climate Change Policy in Germany and the United States,    pp. 49–57. German-American Academic Council Foundation: Washington, DC.
                     Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010 738    Critical Sociology 34(5)
Freudenburg, W. and Gramling, R. (2002) Scientific Expertise and Natural Resource Decisions: Social    Science Participation on Interdisciplinary Scientific Committees. Social Science Quarterly 83(1):    119–36. Fuller, S. (2002) Knowledge Management Foundations. Butterworth-Heinemann: Woburn. Fuller, S. (2006) The Philosophy of Science and Technology Studies. Routledge: New York. Gieryn, T. (1983) Boundary-Work and the Demarcation of Science from Non-Science: Strains and    Interests in Professional Ideologies of Scientists. American Sociological Review 48(6): 781–95. Gieryn, T. (1995) Boundaries of Science. S. Jasanoff et al. (eds.) Handbook of Science and Technology    Studies, pp. 393–443. Sage: Thousand Oaks. Gillespie, B., Eva, D. and Johnston, R. (1979) Carcinogenic Risk Assessment in the United States and    Great Britain. Social Studies of Science 9(3): 265–301. Gitlin, T. (1980) The Whole World is Watching. University of California Press: Berkeley. Glantz, S., Slade, J., Bero, L., Hanauer, P. and Barnes, D. (eds) (1996) The Cigarette Papers. University    of California Press: Berkeley. Haack, S. (2003) Defending Science – Within Reason: Between Scientism and Cynicism. Prometheus:    Amherst. Haack, S. (2005) Trial and Error: The Supreme’s Court’s Philosophy of Science. American Journal of    Public Health 95(S1): S66–73. Haraway, D. (1991) Simians, Cyborgs, and Women: The Reinvention of Nature. Routledge: New York. Harding, S. (1991) Whose Science? Whose Knowledge?: Thinking from Women’s Lives. Cornell University    Press: Ithaca. Hendry, A., Vamosi, S., Latham, S., Heibuth, J. and Day, T. (2000) Questioning Species Realities.    Conservation Genetics 1(1): 67–76. Hey, J. (2001) Genes, Categories, and Species: The Evolutionary and Cognitive Causes of the Species Problem.    Oxford University Press: New York. Huber, P. (1999) Hard Green: Saving the Environment from Environmentalists: A Conservative Manifesto.    Basic Books: New York. Isacc, N., Mallet, J. and Mace, G. (2004) Taxonomic Inflation: Its Influence on Macroecology and    Conservation. Trends in Ecology and Evolution 19(9): 464–9. Jasanoff, S. (1986) Risk Management and Political Culture. Russell Sage Foundation: New York. Jasanoff, S. (1987a) Contested Boundaries in Policy-Relevant Science. Social Studies of Science    17(2):195–230. Jasanoff, S. (1987b) Cultural Aspects of Risk Assessment in Britain and the United States. B. Johnson    and V. Covello (eds) The Social and Culture Construction of Risk: Essays of Risk Selection and Perception,    pp. 359–97. Reidel: Dordrecht. Jasanoff, S. (1995) Product, Process, or Programme: Three Cultures and the Regulation of    Biotechnology. M. Bauer (ed.) Resistance to New Technology, pp. 311–31. Cambridge University Press:    Cambridge. Jasanoff, S. (1999) The Songlines of Risk. Environmental Values 8(2): 135–52. Jasanoff, S. (2005a) Designs on Nature: Science and Democracy in Europe and United States. Princeton    University Press: Princeton. Jasanoff, S. (2005b) Law’s Knowledge: Science for Justice in Legal Studies. American Journal of Public    Health 95(S1): S49-S58. Jasanoff, S. and Wynne, B. (1998) Science Knowledge and Decision Making. S. Rayner and E. Malone    (eds) Human Choice and Climate Change, pp. 1–112. Battelle Press: Columbus. Kapustka, L. and Landis, W. (1998) Ecology: The Science Versus the Myth. Human and Ecological Risk    Assessment 4(4): 829–38.
            Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010                                                                     Carolan: Environmental Controversies 739
Kitcher, P. (2001) Science, Truth, and Democracy. Oxford University Press: Oxford. Kleinman, D. (1995) Politics on the Endless Frontier: Post-War Research Policy in the United States. Duke   University Press: Durham. Kraft, M.E. (2000) US Environmental Policy and Politics. Journal of Policy History 12(1): 17–42. Kuhn, T.S. (1970 [1962]). The Structure of Scientific Revolutions. University of Chicago Press: Chicago. Lackey, R. (2001) Values, Policy, and Ecosystem Health. BioScience 51(6): 437–43. Lancaster, J. (2000) The Ridiculous Notion of Assessing Ecological Health and Identifying the Useful   Concepts Underneath. Human and Ecological Risk Assessment 6(2): 213–22. Latour, B. (1992) Give me a Laboratory and I Will Raise the World. M. Biagol (ed.) The Science Studies   Reader, pp. 258–75. Routledge: New York. Law, J. and Urry, J. (2004) Enacting the Social. Economy and Society 33(3): 390–410. Lomborg, B. (2001) The Skeptical Environmentalist. Cambridge University Press: Cambridge. McAfee, K. (2003) Corn Culture and Dangerous DNA: Real and Imagined Consequences of Maize   Transgene Flow in Oaxaca. Journal of Latin American Geography 2(1): 18–42. McCright, A. and Dunlap, R. (2000) Challenging Global Warming as a Social Problem: An Analysis of   the Conservative Movement’s Counter-Claims. Social Problems 47(4): 499–522. McCright A. and Dunlap, R. (2003) Defeating Kyoto: The Conservative Movement’s Impact on US   Climate Change Policy. Social Problems 50(3): 348–73. Mayr, E. (1970) Populations, Species, and Evolution. Harvard University Press: Cambridge. Mol, A. (2002) The Body Multiple: Ontology in Medical Practice. Duke University Press: Durham. Mulkay, M. (1976) Norms and Ideology in Science. Social Science Information 15(4): 637–56. Oreskes, N. (1999) The Rejection of Continental Drift: Theory and Method in American Earth Science.   Oxford University Press: New York. Oreskes, N. (2004a) Science and Public Policy: What’s Proof Got to Do with It? Environmental Science   and Policy 7(5): 369–83. Oreskes, N. (2004b) Beyond the Ivory Tower: The Scientific Consensus on Climate Change. Science   306(5702): 1686. Quist, D. and Chapela, I. (2001) Transgenic DNA Introgressed into Traditional Maize Landraces in   Oaxaca, Mexico. Nature 414(6863): 541–3. Rayner, S. (2003) Democracy in the Age of Assessment: Reflections on the Roles of Expertise and   Democracy in Public-Sector Decision Making. Science and Public Policy 30(3): 163–70. Rosenberg, A. (1994) Instrumental Biology or The Disunity of Science. University of Chicago Press:   Chicago. Rowlands, I. (1993) The Fourth Meeting of the Parties to the Montreal Protocol: Report and Reflection.   Environment 35(6): 25–34. Sarewitz, D. (1996) Frontiers of Illusion. Temple University Press: Philadelphia. Sarewitz, D. (2004) How Science Makes Environmental Controversies Worse. Environmental Science and   Policy 7(5): 385–403. Scalera, G. and Karl-Heinz, J. (eds) (2003) Why Expanding Earth: A Book in Honour of Ott Christoph   Hilgenberg. INGV Publishers: Rome. Scott, D. (2003) Science and the Consequences of Mistruct: Lessons from Recent GM Controversies.   Journal of Agricultural and Environmental Ethics 16(6): 569–82. Shackley, S., Young, P., Parkinson, S. and Wynne, B. (1998) Uncertainty, Complexity and Concepts of   Good Science in Climate Change Modelling: Are GCMs the Best Tools? Climate Change 38(2):   159–205. Taylor, P. and Buttel, F. (1992) How Do We Know We Have Global Environmental Problems? Science   and the Globalization of Environmental Discourse. Geoforum 3(3): 227–41.
                     Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010                    740   Critical Sociology 34(5)
                   Timmons Roberts, J. (2001) Global Inequality and Climate Change. Society and Natural Resources 14(6):                      501–9.                    Vaughan, D. (1996) The Challenger Launch Decision: Risky Technology, Culture, and Deviance at NASA.                      University of Chicago Press: Chicago.                    Warner, K. (1986) Selling Smoke: Cigarette Advertising and Public Health. [Health Policy Monograph                      Series] APHA: Washington, DC.                    Wilson, E. (1992) The Diversity of Life. Harvard University Press: Cambridge.                    Wynne, B. (2001) Creating Public Alienation: Expert Cultures of Risk and Ethics on GMOs. Science as                      Culture 10(4): 445–81.                    Wynne, B. (2002) Risk and Environment as Legitimatory Discourses of Technology: Reflexivity Inside                      Out? Current Sociology 50(3): 459–77.                    Yearly, S. (1996) Sociology, Environmentalism, Globalization: Reinventing the Globe. Sage: London.
                   For correspondence: Michael S. Carolan, Department of Sociology, Colorado State University, B236 Clark,                        Fort Collins, CO, 80523–1784, USA. Email: mcarolan@lamar.colostate.edu
                               Downloaded from http://crs.sagepub.com at COLORADO STATE UNIV LIBRARIES on January 25, 2010
View publication stats